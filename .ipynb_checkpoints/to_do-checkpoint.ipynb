{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93aab472-d801-4a1e-8f8a-d7c064390ef3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# A to do list \n",
    "now that the model is trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21341df8-94b3-477b-95c4-8a5fbd0d7235",
   "metadata": {},
   "source": [
    "## tried and failed:\n",
    "\n",
    "- colorize in the same scheme as the training set comes out with pillow.... something has changed. \n",
    "\n",
    "- add a data_augmentation layer for the input (Challet pg 223) but modified for segmentation.\n",
    "\n",
    "- optimize data pipeline \n",
    "    - try that stack overflow folder to dataset code\n",
    "        - looks like this does not work for image segmentation problems because of the two image nature of the datapoints.\n",
    "    - try what Challet does for his segmentation e.g.\n",
    "        - this ammounted to using keras.utils.load_img instead of PIL.Image.open. Applying img_to_array to the results of load_img gives integers like 90,113,28, etc... not the,1,2,3,...,8 I got from img_to_array(PIL.Image.open()). Creation of a np.vectorize version of the functio that takes the new large numbers to 1,...,8 takes a long time... 6 seconds for one image. \n",
    "        \n",
    "- Use flask to host trashnet beta.\n",
    "    - use any version of the model, user uploads photo, site outputs trash mask. \n",
    "    - put trash mask over photo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de384a26-10c0-4532-9493-499d592a9468",
   "metadata": {},
   "source": [
    "## Doing now: \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cdba85-f7ce-4f0f-96f5-5eed592a1dc1",
   "metadata": {},
   "source": [
    "## yet to try\n",
    "\n",
    "\n",
    "\n",
    "- \"this is/is not a picture of the beach.\" classifier filter for the app\n",
    "\n",
    "- use ImageDataGenerator for data augmentation. \n",
    "\n",
    "- keras.applications.mobilenetv2.preprocess_input(image) probabiy give the data pipeline I'm looking for. Documentation says it takes in a tensor or Numpy array... so it is not image to array. What does it do?\n",
    "\n",
    "- Learn about tf data pipeliniung as much as possible by reading Chalet and doing examples.... might as well run more epoch of large trash_net while I work. \n",
    "\n",
    "\n",
    "- why did youtuber leave all layers trainable? \n",
    "\n",
    "- training only a new layer With dropout for regularization.\n",
    "    - read challet\n",
    "\n",
    "- optimize data pipeline \n",
    "    - try cv2 tools. \n",
    "\n",
    "- why does the pretrained NN I'm using get used as inputs fopr even more layers? \n",
    "    - I suppose it is because I get the weights but need to specify how they are connected... but this is so much more complicated than loading a model.\n",
    "\n",
    "\n",
    "- do I load the pretrained model correctly? why doesn't it look like loading a saved model? \n",
    "\n",
    "- Build a layer on top of the pre-trained NN. \n",
    "\n",
    "- lighten the model, perhaps put it on the local device for speed/ pretend to have latency requirements\n",
    "    - try weight pruning ( seems to hard for my tried mind atm)\n",
    "    - try weight quantization \n",
    "\n",
    "- make flahscards for VGG, ResNet, Inception, Xception, and other convnet architectures.\n",
    "\n",
    "\n",
    "\n",
    "### ok for after gc comp\n",
    "\n",
    "- Set a common sense metric:\n",
    "    - 50% accuracy on the pixels labeled as artificail litter.... that it, ignore these vast swaths of sand, sea, and sky. \n",
    "\n",
    "- Proofread labels\n",
    "\n",
    "- how long does an epoch take with \n",
    "    - google CPU 16 GB\n",
    "    - GOOGLE GPU 16GB?\n",
    "    - google TPU 16GB\n",
    "    - TOGLE TPU 128 GB\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "- Overfit, and dial back.\n",
    "\n",
    "- place masks over images, zoom in for yourself so you are not trating the data as a balck box. \n",
    "\n",
    "- in presentation comment on the possibility of concept drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbec7b7-a512-4125-8750-6b58a69da6d0",
   "metadata": {},
   "source": [
    "I want to change all the data types to float 32 beofre I commit to big computation time because \n",
    "- it seems to be th default data type for tensorflow, \n",
    "- is probably good enough accuracy to store all the weights and pixel values. \n",
    "Looks like it worked! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67176f85-d75d-4d28-ba31-be80ebcd9a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c176121-8c80-4930-b66f-dd547d453cf8",
   "metadata": {},
   "source": [
    "## Tried with success: \n",
    "\n",
    "04-13\n",
    "\n",
    "- became confident that I know which layers to freeze. \n",
    "- turn off axes in images. \n",
    "- plotted masks over images\n",
    "- learned that streamlit does not allow pickled keras models, despite someone sayin otherwise on stack oveflow... at least not without import tensorflow . \n",
    "- save a pickled model. It is 8.5MB\n",
    "\n",
    "\n",
    "\n",
    "04-12\n",
    "\n",
    "- know how to look inside the NN\n",
    "    - Make most of the layers not trainable. \n",
    "    - model.weights\n",
    "    - model_c.layers[1].get_weights()\n",
    "    \n",
    "- keras.utils.plot_model(model,\"filename.ext\", showshapes = True)\n",
    "\n",
    "- Save the pre-trained model, its one and two epoch version, etc as h5py or the new tf standard format, reload and continue training. \n",
    "\n",
    "- start a new NB for training a model to the point of overfitting. \n",
    "\n",
    "- try making layers not trainable. \n",
    "     - how do I see which layers to make not trainable\n",
    "\n",
    "- use tensorboard in AI platform. \n",
    "     - for simpler model, \n",
    "\n",
    "- put callback in place\n",
    "\n",
    "04-11\n",
    "- change all dtypes to float32 ( the default for tensorflow) \n",
    "\n",
    "- look for metadata from the images  (there is none... that is useful, like gps coords.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03302363",
   "metadata": {},
   "source": [
    "** new markdown idea: task lists:\n",
    "\n",
    "- [x] GFM task list 1\n",
    "- [x] GFM task list 2\n",
    "- [ ] GFM task list 3\n",
    "    - [ ] GFM task list 3-1\n",
    "    - [ ] GFM task list 3-2\n",
    "    - [ ] GFM task list 3-3\n",
    "- [ ] GFM task list 4\n",
    "    - [ ] GFM task list 4-1\n",
    "    - [ ] GFM task list 4-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08215242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
