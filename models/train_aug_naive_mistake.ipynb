{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888bab52-af9f-43aa-9eed-e07835a7eba0",
   "metadata": {},
   "source": [
    "# Train Full Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07b0695-e1d5-4791-bcd7-be2b97422ce2",
   "metadata": {},
   "source": [
    "In this NB I tried modifying two things\n",
    "1. the data is augmented by a random zoom-plus-flip-plus-rotate tranformation. \n",
    "2. the encoding layers of the NN are frozen.\n",
    "\n",
    "Unfortuately my naive use of the data augmentation did no take into account the need to apply the same tranformation to masks. Still, something useful was learned: accuracy was 80% even when comparing an mask generated by a rotated, zoomed, possibly flipped image. Thus, much of the accuracy comes from the large swaths of constant class. Note that this sould be true of pet segmentation too. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886e5f9-72c3-4207-9d49-e13856b456f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1) Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89b9155f-fd54-4cae-9d36-52df45091a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## retrieve model\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('saved_models/')\n",
    "\n",
    "## even a pre-trained model needs data:\n",
    "\n",
    "# 1. Sort paths to files\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "path = 'beachlitter/'\n",
    "images = sorted(glob(os.path.join(path, \"images/*.jpg\"))) # list of strings\n",
    "masks = sorted(glob(os.path.join(path, \"maskpngs/*.png\"))) \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def sort_paths(path, split=0.1):\n",
    "    # PATH = \"gs://dmcherney/beachlitter/\"\n",
    "    # glob(file_pattern) gives a list of strings satisfying the pattern\n",
    "    images = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "    masks = sorted(glob(os.path.join(path, \"maskpngs/*\")))\n",
    "\n",
    "    total_size = len(images)\n",
    "    valid_size = int(split * total_size)\n",
    "    test_size = int(split * total_size)\n",
    "    \n",
    "    #shuffle with the same random seed to make sure masks stay with images.\n",
    "    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = sort_paths(path)\n",
    "\n",
    "#2 functions to read images: path -> PIL -> array\n",
    "\n",
    "def read_image(path): #takes in a path, gives out a np array\n",
    "    path = path.decode() # neede because this function is in a tf pipe\n",
    "    # open image\n",
    "    im = PIL.Image.open(path).resize((IMAGE_SIZE,IMAGE_SIZE))\n",
    "    # image to tensor\n",
    "    im = tf.keras.utils.img_to_array(im, data_format=None, dtype='float32')\n",
    "    # normalize image\n",
    "    im = im/255.\n",
    "    return im\n",
    "\n",
    "def read_mask(path):\n",
    "    path = path.decode() # neede because this function is in a tf pipe\n",
    "    # open mask\n",
    "    ma = PIL.Image.open(path).resize((IMAGE_SIZE,IMAGE_SIZE))\n",
    "    # mask to tensor\n",
    "    ma = tf.keras.utils.img_to_array(ma, data_format=None, dtype='float32')\n",
    "    # change catagory numbers from 1 to 8 into 0 to 7\n",
    "    ma[:,:,0] -= 1\n",
    "    # one hot encode\n",
    "    ma = to_categorical(ma[:,:,0],num_classes=8, dtype='float32')\n",
    "    return ma\n",
    "\n",
    "# arrays to tensorflow tensors:\n",
    "def tf_parse(x, y): # takes in 2 paths, not lists\n",
    "    def _parse(x, y): # takes in 2 paths\n",
    "        x = read_image(x) \n",
    "        y = read_mask(y)\n",
    "        return x, y # gives out 2 np.arrays\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32]) #takes in 2 paths, gives out 2 tf.tesors\n",
    "    x.set_shape([IMAGE_SIZE, IMAGE_SIZE, 3]) # seems redundant, but for now it is bouble check\n",
    "    y.set_shape([IMAGE_SIZE, IMAGE_SIZE, 8])\n",
    "    return x, y # tf.tesors \n",
    "\n",
    "# 3 organize data into tf dataset of tf tensors\n",
    "def tf_dataset(x, y, batch=8): #takes in x : list of paths, y : list of paths\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset\n",
    "\n",
    "train_dataset = tf_dataset(train_x, train_y) # input: lists of filenames . Output: to batched tf datasets of parsed images\n",
    "valid_dataset = tf_dataset(valid_x, valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b2f1da-963e-444d-820f-8808f927f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network architecture and fitting tools\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D, Input, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau \n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "# from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972edf73-0327-4c98-9924-a312eaaf286b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2) Modify the model to include randomized data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4b08e70-1582-4d89-bb7a-e5b60b380976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "data_augmentation = keras.Sequential([\n",
    "                                    layers.RandomFlip(\"horizontal\",name='hi'),\n",
    "                                    layers.RandomRotation(0.1),\n",
    "                                    layers.RandomZoom(0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b5bf158-9687-411e-b9be-c74aae727051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the pre trained NN not trainable/fixed \n",
    "# inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name=\"input_image\")\n",
    "# randomized_inputs = data_augmentation(inputs)\n",
    "# encoder = MobileNetV2(input_tensor=randomized_inputs, weights=\"imagenet\", include_top=False, alpha=0.35)\n",
    "# encoder.trainable = False\n",
    "# encoder.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "697b4a4c-f5e8-498c-bb1a-14991af84219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2 \n",
    "def model():\n",
    "    inputs = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name=\"input_image\")\n",
    "    randomized_inputs = data_augmentation(inputs)\n",
    "    \n",
    "    # the pre-trained encoder\n",
    "    encoder = MobileNetV2(input_tensor=randomized_inputs, \n",
    "                          weights=\"imagenet\", # instead of randomized initial weights\n",
    "                          include_top=False, # to fully connected softmax layer off. \n",
    "                          alpha=0.35) # proportionally decrease the number of filters in each layer. see paper.\n",
    "    encoder.trainable = False\n",
    "    skip_connection_names = [\"input_image\", \"block_1_expand_relu\", \n",
    "                             \"block_3_expand_relu\", \"block_6_expand_relu\"]\n",
    "    encoder_output = encoder.get_layer(\"block_13_expand_relu\").output\n",
    "    # output of encoder is 16x16 \n",
    "    \n",
    "    # the decoder follows\n",
    "    f = [16, 32, 48, 64] # the numbers of filters to use in skips traveling UP the U \n",
    "    x = encoder_output\n",
    "    for i in range(1, len(skip_connection_names)+1, 1):\n",
    "        x_skip = encoder.get_layer(skip_connection_names[-i]).output\n",
    "        x = UpSampling2D((2, 2))(x)\n",
    "        x = Concatenate()([x, x_skip])\n",
    "        \n",
    "        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "        x = Conv2D(f[-i], (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        \n",
    "    # output layer:\n",
    "    # old version had one class, thus one filter:\n",
    "    # x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
    "    # x = Activation(\"sigmoid\")(x)\n",
    "    x = Conv2D(8, (1, 1), padding=\"same\")(x)\n",
    "    x = Activation(\"softmax\")(x)\n",
    "\n",
    "    \n",
    "    model = Model(inputs, x) # object created\n",
    "    return model # object returned\n",
    "\n",
    "model = model()\n",
    "LR = 1e-4 #learning rate\n",
    "opt = tf.keras.optimizers.Nadam(LR)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0ecb2c7-897d-48ed-88ba-0dbf06037d1d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_____________________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     Trainable  \n",
      "=============================================================================================================\n",
      " input_image (InputLayer)       [(None, 224, 224, 3  0           []                               N          \n",
      "                                )]                                                                           \n",
      "                                                                                                             \n",
      " sequential_3 (Sequential)      (None, 224, 224, 3)  0           ['input_image[0][0]']            N          \n",
      "                                                                                                             \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 16  432         ['sequential_3[2][0]']           N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 16  64          ['Conv1[0][0]']                  N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 16  0           ['bn_Conv1[0][0]']               N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 16  144        ['Conv1_relu[0][0]']             N          \n",
      " wiseConv2D)                    )                                                                            \n",
      "                                                                                                             \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 16  64         ['expanded_conv_depthwise[0][0]  N          \n",
      " tchNormalization)              )                                ']                                          \n",
      "                                                                                                             \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 16  0          ['expanded_conv_depthwise_BN[0]  N          \n",
      " ReLU)                          )                                [0]']                                       \n",
      "                                                                                                             \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 8)  128        ['expanded_conv_depthwise_relu[  N          \n",
      "                                                                 0][0]']                                     \n",
      "                                                                                                             \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 8)  32         ['expanded_conv_project[0][0]']  N          \n",
      " hNormalization)                                                                                             \n",
      "                                                                                                             \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 48  384         ['expanded_conv_project_BN[0][0  N          \n",
      "                                )                                ]']                                         \n",
      "                                                                                                             \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 48  192        ['block_1_expand[0][0]']         N          \n",
      " ization)                       )                                                                            \n",
      "                                                                                                             \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 48  0           ['block_1_expand_BN[0][0]']      N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 48  0           ['block_1_expand_relu[0][0]']    N          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 48)  432         ['block_1_pad[0][0]']            N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 48)  192         ['block_1_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 48)   0           ['block_1_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_1_project (Conv2D)       (None, 56, 56, 8)    384         ['block_1_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 8)   32          ['block_1_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 48)   384         ['block_1_project_BN[0][0]']     N          \n",
      "                                                                                                             \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 48)  192         ['block_2_expand[0][0]']         N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 48)   0           ['block_2_expand_BN[0][0]']      N          \n",
      "                                                                                                             \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 48)  432         ['block_2_expand_relu[0][0]']    N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 48)  192         ['block_2_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 48)   0           ['block_2_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_2_project (Conv2D)       (None, 56, 56, 8)    384         ['block_2_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 8)   32          ['block_2_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_2_add (Add)              (None, 56, 56, 8)    0           ['block_1_project_BN[0][0]',     N          \n",
      "                                                                  'block_2_project_BN[0][0]']                \n",
      "                                                                                                             \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 48)   384         ['block_2_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 48)  192         ['block_3_expand[0][0]']         N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 48)   0           ['block_3_expand_BN[0][0]']      N          \n",
      "                                                                                                             \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 48)   0           ['block_3_expand_relu[0][0]']    N          \n",
      "                                                                                                             \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 48)  432         ['block_3_pad[0][0]']            N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 48)  192         ['block_3_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 48)   0           ['block_3_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_3_project (Conv2D)       (None, 28, 28, 16)   768         ['block_3_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 16)  64          ['block_3_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 96)   1536        ['block_3_project_BN[0][0]']     N          \n",
      "                                                                                                             \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 96)  384         ['block_4_expand[0][0]']         N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 96)   0           ['block_4_expand_BN[0][0]']      N          \n",
      "                                                                                                             \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 96)  864         ['block_4_expand_relu[0][0]']    N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 96)  384         ['block_4_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 96)   0           ['block_4_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_4_project (Conv2D)       (None, 28, 28, 16)   1536        ['block_4_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 16)  64          ['block_4_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_4_add (Add)              (None, 28, 28, 16)   0           ['block_3_project_BN[0][0]',     N          \n",
      "                                                                  'block_4_project_BN[0][0]']                \n",
      "                                                                                                             \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 96)   1536        ['block_4_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 96)  384         ['block_5_expand[0][0]']         N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 96)   0           ['block_5_expand_BN[0][0]']      N          \n",
      "                                                                                                             \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 96)  864         ['block_5_expand_relu[0][0]']    N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 96)  384         ['block_5_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 96)   0           ['block_5_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_5_project (Conv2D)       (None, 28, 28, 16)   1536        ['block_5_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 16)  64          ['block_5_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_5_add (Add)              (None, 28, 28, 16)   0           ['block_4_add[0][0]',            N          \n",
      "                                                                  'block_5_project_BN[0][0]']                \n",
      "                                                                                                             \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 96)   1536        ['block_5_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 96)  384         ['block_6_expand[0][0]']         N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 96)   0           ['block_6_expand_BN[0][0]']      N          \n",
      "                                                                                                             \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 96)   0           ['block_6_expand_relu[0][0]']    N          \n",
      "                                                                                                             \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 96)  864         ['block_6_pad[0][0]']            N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 96)  384         ['block_6_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 96)   0           ['block_6_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_6_project (Conv2D)       (None, 14, 14, 24)   2304        ['block_6_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 24)  96          ['block_6_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 144)  3456        ['block_6_project_BN[0][0]']     N          \n",
      "                                                                                                             \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 144)  576        ['block_7_expand[0][0]']         N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 144)  0           ['block_7_expand_BN[0][0]']      N          \n",
      "                                                                                                             \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 144)  1296       ['block_7_expand_relu[0][0]']    N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 144)  576        ['block_7_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 144)  0           ['block_7_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_7_project (Conv2D)       (None, 14, 14, 24)   3456        ['block_7_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 24)  96          ['block_7_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_7_add (Add)              (None, 14, 14, 24)   0           ['block_6_project_BN[0][0]',     N          \n",
      "                                                                  'block_7_project_BN[0][0]']                \n",
      "                                                                                                             \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 144)  3456        ['block_7_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 144)  576        ['block_8_expand[0][0]']         N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 144)  0           ['block_8_expand_BN[0][0]']      N          \n",
      "                                                                                                             \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 144)  1296       ['block_8_expand_relu[0][0]']    N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 144)  576        ['block_8_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 144)  0           ['block_8_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_8_project (Conv2D)       (None, 14, 14, 24)   3456        ['block_8_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 24)  96          ['block_8_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_8_add (Add)              (None, 14, 14, 24)   0           ['block_7_add[0][0]',            N          \n",
      "                                                                  'block_8_project_BN[0][0]']                \n",
      "                                                                                                             \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 144)  3456        ['block_8_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 144)  576        ['block_9_expand[0][0]']         N          \n",
      " ization)                                                                                                    \n",
      "                                                                                                             \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 144)  0           ['block_9_expand_BN[0][0]']      N          \n",
      "                                                                                                             \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 144)  1296       ['block_9_expand_relu[0][0]']    N          \n",
      " nv2D)                                                                                                       \n",
      "                                                                                                             \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 144)  576        ['block_9_depthwise[0][0]']      N          \n",
      " malization)                                                                                                 \n",
      "                                                                                                             \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 144)  0           ['block_9_depthwise_BN[0][0]']   N          \n",
      "                                                                                                             \n",
      " block_9_project (Conv2D)       (None, 14, 14, 24)   3456        ['block_9_depthwise_relu[0][0]'  N          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 24)  96          ['block_9_project[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_9_add (Add)              (None, 14, 14, 24)   0           ['block_8_add[0][0]',            N          \n",
      "                                                                  'block_9_project_BN[0][0]']                \n",
      "                                                                                                             \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 144)  3456        ['block_9_add[0][0]']            N          \n",
      "                                                                                                             \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 144)  576        ['block_10_expand[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 144)  0           ['block_10_expand_BN[0][0]']     N          \n",
      "                                                                                                             \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 144)  1296       ['block_10_expand_relu[0][0]']   N          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 144)  576        ['block_10_depthwise[0][0]']     N          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 144)  0          ['block_10_depthwise_BN[0][0]']  N          \n",
      "                                                                                                             \n",
      " block_10_project (Conv2D)      (None, 14, 14, 32)   4608        ['block_10_depthwise_relu[0][0]  N          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 32)  128         ['block_10_project[0][0]']       N          \n",
      " alization)                                                                                                  \n",
      "                                                                                                             \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 192)  6144        ['block_10_project_BN[0][0]']    N          \n",
      "                                                                                                             \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 192)  768        ['block_11_expand[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 192)  0           ['block_11_expand_BN[0][0]']     N          \n",
      "                                                                                                             \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 192)  1728       ['block_11_expand_relu[0][0]']   N          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 192)  768        ['block_11_depthwise[0][0]']     N          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 192)  0          ['block_11_depthwise_BN[0][0]']  N          \n",
      "                                                                                                             \n",
      " block_11_project (Conv2D)      (None, 14, 14, 32)   6144        ['block_11_depthwise_relu[0][0]  N          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 32)  128         ['block_11_project[0][0]']       N          \n",
      " alization)                                                                                                  \n",
      "                                                                                                             \n",
      " block_11_add (Add)             (None, 14, 14, 32)   0           ['block_10_project_BN[0][0]',    N          \n",
      "                                                                  'block_11_project_BN[0][0]']               \n",
      "                                                                                                             \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 192)  6144        ['block_11_add[0][0]']           N          \n",
      "                                                                                                             \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 192)  768        ['block_12_expand[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 192)  0           ['block_12_expand_BN[0][0]']     N          \n",
      "                                                                                                             \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 192)  1728       ['block_12_expand_relu[0][0]']   N          \n",
      " onv2D)                                                                                                      \n",
      "                                                                                                             \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 192)  768        ['block_12_depthwise[0][0]']     N          \n",
      " rmalization)                                                                                                \n",
      "                                                                                                             \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 192)  0          ['block_12_depthwise_BN[0][0]']  N          \n",
      "                                                                                                             \n",
      " block_12_project (Conv2D)      (None, 14, 14, 32)   6144        ['block_12_depthwise_relu[0][0]  N          \n",
      "                                                                 ']                                          \n",
      "                                                                                                             \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 32)  128         ['block_12_project[0][0]']       N          \n",
      " alization)                                                                                                  \n",
      "                                                                                                             \n",
      " block_12_add (Add)             (None, 14, 14, 32)   0           ['block_11_add[0][0]',           N          \n",
      "                                                                  'block_12_project_BN[0][0]']               \n",
      "                                                                                                             \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 192)  6144        ['block_12_add[0][0]']           N          \n",
      "                                                                                                             \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 192)  768        ['block_13_expand[0][0]']        N          \n",
      " lization)                                                                                                   \n",
      "                                                                                                             \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 192)  0           ['block_13_expand_BN[0][0]']     N          \n",
      "                                                                                                             \n",
      " up_sampling2d_20 (UpSampling2D  (None, 28, 28, 192)  0          ['block_13_expand_relu[0][0]']   Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " concatenate_20 (Concatenate)   (None, 28, 28, 288)  0           ['up_sampling2d_20[0][0]',       Y          \n",
      "                                                                  'block_6_expand_relu[0][0]']               \n",
      "                                                                                                             \n",
      " conv2d_45 (Conv2D)             (None, 28, 28, 64)   165952      ['concatenate_20[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_40 (BatchN  (None, 28, 28, 64)  256         ['conv2d_45[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_45 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_40[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_46 (Conv2D)             (None, 28, 28, 64)   36928       ['activation_45[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_41 (BatchN  (None, 28, 28, 64)  256         ['conv2d_46[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_46 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_41[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " up_sampling2d_21 (UpSampling2D  (None, 56, 56, 64)  0           ['activation_46[0][0]']          Y          \n",
      " )                                                                                                           \n",
      "                                                                                                             \n",
      " concatenate_21 (Concatenate)   (None, 56, 56, 112)  0           ['up_sampling2d_21[0][0]',       Y          \n",
      "                                                                  'block_3_expand_relu[0][0]']               \n",
      "                                                                                                             \n",
      " conv2d_47 (Conv2D)             (None, 56, 56, 48)   48432       ['concatenate_21[0][0]']         Y          \n",
      "                                                                                                             \n",
      " batch_normalization_42 (BatchN  (None, 56, 56, 48)  192         ['conv2d_47[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_47 (Activation)     (None, 56, 56, 48)   0           ['batch_normalization_42[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " conv2d_48 (Conv2D)             (None, 56, 56, 48)   20784       ['activation_47[0][0]']          Y          \n",
      "                                                                                                             \n",
      " batch_normalization_43 (BatchN  (None, 56, 56, 48)  192         ['conv2d_48[0][0]']              Y          \n",
      " ormalization)                                                                                               \n",
      "                                                                                                             \n",
      " activation_48 (Activation)     (None, 56, 56, 48)   0           ['batch_normalization_43[0][0]'  Y          \n",
      "                                                                 ]                                           \n",
      "                                                                                                             \n",
      " up_sampling2d_22 (UpSampling2D  (None, 112, 112, 48  0          ['activation_48[0][0]']          Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " concatenate_22 (Concatenate)   (None, 112, 112, 96  0           ['up_sampling2d_22[0][0]',       Y          \n",
      "                                )                                 'block_1_expand_relu[0][0]']               \n",
      "                                                                                                             \n",
      " conv2d_49 (Conv2D)             (None, 112, 112, 32  27680       ['concatenate_22[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " batch_normalization_44 (BatchN  (None, 112, 112, 32  128        ['conv2d_49[0][0]']              Y          \n",
      " ormalization)                  )                                                                            \n",
      "                                                                                                             \n",
      " activation_49 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_44[0][0]'  Y          \n",
      "                                )                                ]                                           \n",
      "                                                                                                             \n",
      " conv2d_50 (Conv2D)             (None, 112, 112, 32  9248        ['activation_49[0][0]']          Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " batch_normalization_45 (BatchN  (None, 112, 112, 32  128        ['conv2d_50[0][0]']              Y          \n",
      " ormalization)                  )                                                                            \n",
      "                                                                                                             \n",
      " activation_50 (Activation)     (None, 112, 112, 32  0           ['batch_normalization_45[0][0]'  Y          \n",
      "                                )                                ]                                           \n",
      "                                                                                                             \n",
      " up_sampling2d_23 (UpSampling2D  (None, 224, 224, 32  0          ['activation_50[0][0]']          Y          \n",
      " )                              )                                                                            \n",
      "                                                                                                             \n",
      " concatenate_23 (Concatenate)   (None, 224, 224, 35  0           ['up_sampling2d_23[0][0]',       Y          \n",
      "                                )                                 'input_image[0][0]']                       \n",
      "                                                                                                             \n",
      " conv2d_51 (Conv2D)             (None, 224, 224, 16  5056        ['concatenate_23[0][0]']         Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " batch_normalization_46 (BatchN  (None, 224, 224, 16  64         ['conv2d_51[0][0]']              Y          \n",
      " ormalization)                  )                                                                            \n",
      "                                                                                                             \n",
      " activation_51 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_46[0][0]'  Y          \n",
      "                                )                                ]                                           \n",
      "                                                                                                             \n",
      " conv2d_52 (Conv2D)             (None, 224, 224, 16  2320        ['activation_51[0][0]']          Y          \n",
      "                                )                                                                            \n",
      "                                                                                                             \n",
      " batch_normalization_47 (BatchN  (None, 224, 224, 16  64         ['conv2d_52[0][0]']              Y          \n",
      " ormalization)                  )                                                                            \n",
      "                                                                                                             \n",
      " activation_52 (Activation)     (None, 224, 224, 16  0           ['batch_normalization_47[0][0]'  Y          \n",
      "                                )                                ]                                           \n",
      "                                                                                                             \n",
      " conv2d_53 (Conv2D)             (None, 224, 224, 8)  136         ['activation_52[0][0]']          Y          \n",
      "                                                                                                             \n",
      " activation_53 (Activation)     (None, 224, 224, 8)  0           ['conv2d_53[0][0]']              Y          \n",
      "                                                                                                             \n",
      "=============================================================================================================\n",
      "Total params: 416,328\n",
      "Trainable params: 317,176\n",
      "Non-trainable params: 99,152\n",
      "_____________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(show_trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ee22ff-7a6e-42d7-9f99-d914a9d5b020",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3) Train with the fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11777704-d571-4ee1-af71-d8f45abd1570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/48\n",
      "350/350 [==============================] - 558s 2s/step - loss: 0.9787 - accuracy: 0.7270 - val_loss: 0.8329 - val_accuracy: 0.7749 - lr: 1.0000e-04\n",
      "Epoch 2/48\n",
      "350/350 [==============================] - 580s 2s/step - loss: 0.8825 - accuracy: 0.7453 - val_loss: 0.7516 - val_accuracy: 0.8024 - lr: 1.0000e-04\n",
      "Epoch 3/48\n",
      "350/350 [==============================] - 567s 2s/step - loss: 0.8078 - accuracy: 0.7616 - val_loss: 0.6900 - val_accuracy: 0.8019 - lr: 1.0000e-04\n",
      "Epoch 4/48\n",
      "350/350 [==============================] - 575s 2s/step - loss: 0.7571 - accuracy: 0.7712 - val_loss: 0.6747 - val_accuracy: 0.8092 - lr: 1.0000e-04\n",
      "Epoch 5/48\n",
      "350/350 [==============================] - 575s 2s/step - loss: 0.7209 - accuracy: 0.7783 - val_loss: 0.6265 - val_accuracy: 0.8272 - lr: 1.0000e-04\n",
      "Epoch 6/48\n",
      "350/350 [==============================] - 607s 2s/step - loss: 0.6963 - accuracy: 0.7827 - val_loss: 0.6052 - val_accuracy: 0.8213 - lr: 1.0000e-04\n",
      "Epoch 7/48\n",
      "350/350 [==============================] - 670s 2s/step - loss: 0.6772 - accuracy: 0.7863 - val_loss: 0.5867 - val_accuracy: 0.8224 - lr: 1.0000e-04\n",
      "Epoch 8/48\n",
      "350/350 [==============================] - 632s 2s/step - loss: 0.6611 - accuracy: 0.7898 - val_loss: 0.5686 - val_accuracy: 0.8252 - lr: 1.0000e-04\n",
      "Epoch 9/48\n",
      "350/350 [==============================] - 584s 2s/step - loss: 0.6505 - accuracy: 0.7922 - val_loss: 0.5519 - val_accuracy: 0.8283 - lr: 1.0000e-04\n",
      "Epoch 10/48\n",
      "350/350 [==============================] - 597s 2s/step - loss: 0.6357 - accuracy: 0.7960 - val_loss: 0.5472 - val_accuracy: 0.8300 - lr: 1.0000e-04\n",
      "Epoch 11/48\n",
      "350/350 [==============================] - 597s 2s/step - loss: 0.6291 - accuracy: 0.7970 - val_loss: 0.5244 - val_accuracy: 0.8355 - lr: 1.0000e-04\n",
      "Epoch 12/48\n",
      "350/350 [==============================] - 580s 2s/step - loss: 0.6208 - accuracy: 0.7997 - val_loss: 0.5582 - val_accuracy: 0.8235 - lr: 1.0000e-04\n",
      "Epoch 13/48\n",
      "350/350 [==============================] - 578s 2s/step - loss: 0.6158 - accuracy: 0.8000 - val_loss: 0.5415 - val_accuracy: 0.8272 - lr: 1.0000e-04\n",
      "Epoch 14/48\n",
      "350/350 [==============================] - 574s 2s/step - loss: 0.6071 - accuracy: 0.8033 - val_loss: 0.5339 - val_accuracy: 0.8308 - lr: 1.0000e-04\n",
      "Epoch 15/48\n",
      "350/350 [==============================] - 556s 2s/step - loss: 0.6012 - accuracy: 0.8043 - val_loss: 0.5353 - val_accuracy: 0.8322 - lr: 1.0000e-04\n",
      "Epoch 16/48\n",
      "350/350 [==============================] - 579s 2s/step - loss: 0.5903 - accuracy: 0.8083 - val_loss: 0.5127 - val_accuracy: 0.8368 - lr: 1.0000e-05\n",
      "Epoch 17/48\n",
      "350/350 [==============================] - 588s 2s/step - loss: 0.5866 - accuracy: 0.8086 - val_loss: 0.5127 - val_accuracy: 0.8360 - lr: 1.0000e-05\n",
      "Epoch 18/48\n",
      "350/350 [==============================] - 559s 2s/step - loss: 0.5823 - accuracy: 0.8106 - val_loss: 0.5102 - val_accuracy: 0.8372 - lr: 1.0000e-05\n",
      "Epoch 19/48\n",
      "350/350 [==============================] - 599s 2s/step - loss: 0.5821 - accuracy: 0.8102 - val_loss: 0.5123 - val_accuracy: 0.8364 - lr: 1.0000e-05\n",
      "Epoch 20/48\n",
      "350/350 [==============================] - 579s 2s/step - loss: 0.5834 - accuracy: 0.8099 - val_loss: 0.5083 - val_accuracy: 0.8372 - lr: 1.0000e-05\n",
      "Epoch 21/48\n",
      "350/350 [==============================] - 562s 2s/step - loss: 0.5828 - accuracy: 0.8101 - val_loss: 0.5101 - val_accuracy: 0.8370 - lr: 1.0000e-05\n",
      "Epoch 22/48\n",
      "350/350 [==============================] - 593s 2s/step - loss: 0.5810 - accuracy: 0.8111 - val_loss: 0.5096 - val_accuracy: 0.8363 - lr: 1.0000e-05\n",
      "Epoch 23/48\n",
      "350/350 [==============================] - 575s 2s/step - loss: 0.5822 - accuracy: 0.8103 - val_loss: 0.5080 - val_accuracy: 0.8374 - lr: 1.0000e-05\n",
      "Epoch 24/48\n",
      "350/350 [==============================] - 556s 2s/step - loss: 0.5783 - accuracy: 0.8119 - val_loss: 0.5095 - val_accuracy: 0.8371 - lr: 1.0000e-05\n",
      "Epoch 25/48\n",
      "350/350 [==============================] - 557s 2s/step - loss: 0.5800 - accuracy: 0.8105 - val_loss: 0.5093 - val_accuracy: 0.8368 - lr: 1.0000e-05\n",
      "Epoch 26/48\n",
      "350/350 [==============================] - 578s 2s/step - loss: 0.5795 - accuracy: 0.8104 - val_loss: 0.5103 - val_accuracy: 0.8363 - lr: 1.0000e-05\n",
      "Epoch 27/48\n",
      "350/350 [==============================] - 557s 2s/step - loss: 0.5791 - accuracy: 0.8103 - val_loss: 0.5066 - val_accuracy: 0.8373 - lr: 1.0000e-05\n",
      "Epoch 28/48\n",
      "350/350 [==============================] - 570s 2s/step - loss: 0.5768 - accuracy: 0.8118 - val_loss: 0.5036 - val_accuracy: 0.8389 - lr: 1.0000e-05\n",
      "Epoch 29/48\n",
      "350/350 [==============================] - 552s 2s/step - loss: 0.5776 - accuracy: 0.8116 - val_loss: 0.5068 - val_accuracy: 0.8374 - lr: 1.0000e-05\n",
      "Epoch 30/48\n",
      "350/350 [==============================] - 555s 2s/step - loss: 0.5773 - accuracy: 0.8117 - val_loss: 0.5065 - val_accuracy: 0.8377 - lr: 1.0000e-05\n",
      "Epoch 31/48\n",
      "350/350 [==============================] - 570s 2s/step - loss: 0.5719 - accuracy: 0.8131 - val_loss: 0.4987 - val_accuracy: 0.8391 - lr: 1.0000e-06\n",
      "Epoch 42/48\n",
      "350/350 [==============================] - 562s 2s/step - loss: 0.5730 - accuracy: 0.8124 - val_loss: 0.4993 - val_accuracy: 0.8389 - lr: 1.0000e-06\n",
      "Epoch 43/48\n",
      "350/350 [==============================] - 561s 2s/step - loss: 0.5713 - accuracy: 0.8131 - val_loss: 0.5000 - val_accuracy: 0.8387 - lr: 1.0000e-06\n",
      "Epoch 44/48\n",
      "350/350 [==============================] - 544s 2s/step - loss: 0.5723 - accuracy: 0.8130 - val_loss: 0.4995 - val_accuracy: 0.8388 - lr: 1.0000e-06\n",
      "Epoch 45/48\n",
      "350/350 [==============================] - 545s 2s/step - loss: 0.5698 - accuracy: 0.8138 - val_loss: 0.4995 - val_accuracy: 0.8387 - lr: 1.0000e-07\n",
      "Epoch 46/48\n",
      "350/350 [==============================] - 541s 2s/step - loss: 0.5697 - accuracy: 0.8137 - val_loss: 0.4991 - val_accuracy: 0.8389 - lr: 1.0000e-07\n",
      "Epoch 47/48\n",
      "350/350 [==============================] - 558s 2s/step - loss: 0.5695 - accuracy: 0.8140 - val_loss: 0.4993 - val_accuracy: 0.8388 - lr: 1.0000e-07\n",
      "Epoch 48/48\n",
      "350/350 [==============================] - 547s 2s/step - loss: 0.5690 - accuracy: 0.8140 - val_loss: 0.4996 - val_accuracy: 0.8387 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "# options first:\n",
    "LR = 1e-4 #learning rate\n",
    "opt = tf.keras.optimizers.Nadam(LR)\n",
    "BATCH = 8 \n",
    "train_steps = len(train_x)//BATCH\n",
    "valid_steps = len(valid_x)//BATCH\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") # for tensorboard logs\n",
    "callbacks_list = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n",
    "    # EarlyStopping(monitor='val_loss', \n",
    "    #               patience=5, \n",
    "    #               restore_best_weights=True # lets me save the model.\n",
    "    #                      ),\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1, #for histogram computation each epoc \n",
    "                              )\n",
    "]\n",
    "\n",
    "#call fit\n",
    "res = model.fit(\n",
    "    train_dataset, # this actas as both X and y\n",
    "    validation_data=valid_dataset,\n",
    "    epochs = 48,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_steps=valid_steps,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "267fc89e-bfc9-49df-a297-f6eee22c0ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e574df5f-a9b3-4a74-bcb0-332e2e8edb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5131046e-ecab-40ba-8903-0ef9d6fe2739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.450202</td>\n",
       "      <td>0.606081</td>\n",
       "      <td>1.213300</td>\n",
       "      <td>0.709890</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.122983</td>\n",
       "      <td>0.695922</td>\n",
       "      <td>0.919184</td>\n",
       "      <td>0.769601</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy      lr\n",
       "0  1.450202  0.606081  1.213300      0.709890  0.0001\n",
       "1  1.122983  0.695922  0.919184      0.769601  0.0001"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# scores= pd.DataFrame(data=res.history)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb0272e4-00b3-4ce8-9eb3-7766caa949da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.450202</td>\n",
       "      <td>0.606081</td>\n",
       "      <td>1.213300</td>\n",
       "      <td>0.709890</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.122983</td>\n",
       "      <td>0.695922</td>\n",
       "      <td>0.919184</td>\n",
       "      <td>0.769601</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978668</td>\n",
       "      <td>0.726972</td>\n",
       "      <td>0.832907</td>\n",
       "      <td>0.774889</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.882526</td>\n",
       "      <td>0.745291</td>\n",
       "      <td>0.751570</td>\n",
       "      <td>0.802365</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.807813</td>\n",
       "      <td>0.761615</td>\n",
       "      <td>0.689994</td>\n",
       "      <td>0.801884</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757135</td>\n",
       "      <td>0.771211</td>\n",
       "      <td>0.674660</td>\n",
       "      <td>0.809212</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.720943</td>\n",
       "      <td>0.778257</td>\n",
       "      <td>0.626456</td>\n",
       "      <td>0.827163</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.696332</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.605159</td>\n",
       "      <td>0.821280</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.677193</td>\n",
       "      <td>0.786322</td>\n",
       "      <td>0.586736</td>\n",
       "      <td>0.822375</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.661110</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.568635</td>\n",
       "      <td>0.825163</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.650455</td>\n",
       "      <td>0.792218</td>\n",
       "      <td>0.551924</td>\n",
       "      <td>0.828305</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.635724</td>\n",
       "      <td>0.796020</td>\n",
       "      <td>0.547248</td>\n",
       "      <td>0.830046</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.629129</td>\n",
       "      <td>0.797030</td>\n",
       "      <td>0.524373</td>\n",
       "      <td>0.835478</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.620842</td>\n",
       "      <td>0.799723</td>\n",
       "      <td>0.558209</td>\n",
       "      <td>0.823523</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.615826</td>\n",
       "      <td>0.800003</td>\n",
       "      <td>0.541549</td>\n",
       "      <td>0.827242</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.607053</td>\n",
       "      <td>0.803315</td>\n",
       "      <td>0.533922</td>\n",
       "      <td>0.830845</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.601200</td>\n",
       "      <td>0.804273</td>\n",
       "      <td>0.535283</td>\n",
       "      <td>0.832205</td>\n",
       "      <td>1.000000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.590322</td>\n",
       "      <td>0.808261</td>\n",
       "      <td>0.512739</td>\n",
       "      <td>0.836795</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.586558</td>\n",
       "      <td>0.808621</td>\n",
       "      <td>0.512681</td>\n",
       "      <td>0.836020</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.582311</td>\n",
       "      <td>0.810572</td>\n",
       "      <td>0.510243</td>\n",
       "      <td>0.837199</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.582063</td>\n",
       "      <td>0.810174</td>\n",
       "      <td>0.512261</td>\n",
       "      <td>0.836401</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.583423</td>\n",
       "      <td>0.809891</td>\n",
       "      <td>0.508261</td>\n",
       "      <td>0.837184</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.582784</td>\n",
       "      <td>0.810103</td>\n",
       "      <td>0.510063</td>\n",
       "      <td>0.837015</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.580968</td>\n",
       "      <td>0.811081</td>\n",
       "      <td>0.509582</td>\n",
       "      <td>0.836253</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.582222</td>\n",
       "      <td>0.810298</td>\n",
       "      <td>0.507987</td>\n",
       "      <td>0.837404</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.578266</td>\n",
       "      <td>0.811862</td>\n",
       "      <td>0.509537</td>\n",
       "      <td>0.837073</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.580035</td>\n",
       "      <td>0.810546</td>\n",
       "      <td>0.509339</td>\n",
       "      <td>0.836806</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.579502</td>\n",
       "      <td>0.810449</td>\n",
       "      <td>0.510331</td>\n",
       "      <td>0.836343</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.579135</td>\n",
       "      <td>0.810280</td>\n",
       "      <td>0.506629</td>\n",
       "      <td>0.837276</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.576831</td>\n",
       "      <td>0.811806</td>\n",
       "      <td>0.503573</td>\n",
       "      <td>0.838874</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.577646</td>\n",
       "      <td>0.811624</td>\n",
       "      <td>0.506787</td>\n",
       "      <td>0.837382</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.577328</td>\n",
       "      <td>0.811695</td>\n",
       "      <td>0.506547</td>\n",
       "      <td>0.837682</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.575466</td>\n",
       "      <td>0.812271</td>\n",
       "      <td>0.504644</td>\n",
       "      <td>0.838120</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.573639</td>\n",
       "      <td>0.812618</td>\n",
       "      <td>0.502685</td>\n",
       "      <td>0.839288</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.575824</td>\n",
       "      <td>0.812544</td>\n",
       "      <td>0.506039</td>\n",
       "      <td>0.837825</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.573539</td>\n",
       "      <td>0.812728</td>\n",
       "      <td>0.504601</td>\n",
       "      <td>0.838335</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.572507</td>\n",
       "      <td>0.813110</td>\n",
       "      <td>0.507459</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.574673</td>\n",
       "      <td>0.812053</td>\n",
       "      <td>0.503787</td>\n",
       "      <td>0.838080</td>\n",
       "      <td>1.000000e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.572901</td>\n",
       "      <td>0.812912</td>\n",
       "      <td>0.501106</td>\n",
       "      <td>0.838559</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.572479</td>\n",
       "      <td>0.812561</td>\n",
       "      <td>0.499855</td>\n",
       "      <td>0.838900</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.572343</td>\n",
       "      <td>0.813112</td>\n",
       "      <td>0.499211</td>\n",
       "      <td>0.839034</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.570565</td>\n",
       "      <td>0.813280</td>\n",
       "      <td>0.498555</td>\n",
       "      <td>0.839232</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.571905</td>\n",
       "      <td>0.813147</td>\n",
       "      <td>0.498695</td>\n",
       "      <td>0.839132</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.572994</td>\n",
       "      <td>0.812424</td>\n",
       "      <td>0.499348</td>\n",
       "      <td>0.838915</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.571309</td>\n",
       "      <td>0.813074</td>\n",
       "      <td>0.499981</td>\n",
       "      <td>0.838698</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.572335</td>\n",
       "      <td>0.813037</td>\n",
       "      <td>0.499490</td>\n",
       "      <td>0.838790</td>\n",
       "      <td>1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.569765</td>\n",
       "      <td>0.813773</td>\n",
       "      <td>0.499492</td>\n",
       "      <td>0.838749</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.569673</td>\n",
       "      <td>0.813733</td>\n",
       "      <td>0.499142</td>\n",
       "      <td>0.838874</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.569507</td>\n",
       "      <td>0.813960</td>\n",
       "      <td>0.499262</td>\n",
       "      <td>0.838827</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.568974</td>\n",
       "      <td>0.814016</td>\n",
       "      <td>0.499555</td>\n",
       "      <td>0.838696</td>\n",
       "      <td>1.000000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy            lr\n",
       "0   1.450202  0.606081  1.213300      0.709890  1.000000e-04\n",
       "1   1.122983  0.695922  0.919184      0.769601  1.000000e-04\n",
       "0   0.978668  0.726972  0.832907      0.774889  1.000000e-04\n",
       "1   0.882526  0.745291  0.751570      0.802365  1.000000e-04\n",
       "2   0.807813  0.761615  0.689994      0.801884  1.000000e-04\n",
       "3   0.757135  0.771211  0.674660      0.809212  1.000000e-04\n",
       "4   0.720943  0.778257  0.626456      0.827163  1.000000e-04\n",
       "5   0.696332  0.782716  0.605159      0.821280  1.000000e-04\n",
       "6   0.677193  0.786322  0.586736      0.822375  1.000000e-04\n",
       "7   0.661110  0.789802  0.568635      0.825163  1.000000e-04\n",
       "8   0.650455  0.792218  0.551924      0.828305  1.000000e-04\n",
       "9   0.635724  0.796020  0.547248      0.830046  1.000000e-04\n",
       "10  0.629129  0.797030  0.524373      0.835478  1.000000e-04\n",
       "11  0.620842  0.799723  0.558209      0.823523  1.000000e-04\n",
       "12  0.615826  0.800003  0.541549      0.827242  1.000000e-04\n",
       "13  0.607053  0.803315  0.533922      0.830845  1.000000e-04\n",
       "14  0.601200  0.804273  0.535283      0.832205  1.000000e-04\n",
       "15  0.590322  0.808261  0.512739      0.836795  1.000000e-05\n",
       "16  0.586558  0.808621  0.512681      0.836020  1.000000e-05\n",
       "17  0.582311  0.810572  0.510243      0.837199  1.000000e-05\n",
       "18  0.582063  0.810174  0.512261      0.836401  1.000000e-05\n",
       "19  0.583423  0.809891  0.508261      0.837184  1.000000e-05\n",
       "20  0.582784  0.810103  0.510063      0.837015  1.000000e-05\n",
       "21  0.580968  0.811081  0.509582      0.836253  1.000000e-05\n",
       "22  0.582222  0.810298  0.507987      0.837404  1.000000e-05\n",
       "23  0.578266  0.811862  0.509537      0.837073  1.000000e-05\n",
       "24  0.580035  0.810546  0.509339      0.836806  1.000000e-05\n",
       "25  0.579502  0.810449  0.510331      0.836343  1.000000e-05\n",
       "26  0.579135  0.810280  0.506629      0.837276  1.000000e-05\n",
       "27  0.576831  0.811806  0.503573      0.838874  1.000000e-05\n",
       "28  0.577646  0.811624  0.506787      0.837382  1.000000e-05\n",
       "29  0.577328  0.811695  0.506547      0.837682  1.000000e-05\n",
       "30  0.575466  0.812271  0.504644      0.838120  1.000000e-05\n",
       "31  0.573639  0.812618  0.502685      0.839288  1.000000e-05\n",
       "32  0.575824  0.812544  0.506039      0.837825  1.000000e-05\n",
       "33  0.573539  0.812728  0.504601      0.838335  1.000000e-05\n",
       "34  0.572507  0.813110  0.507459      0.837234  1.000000e-05\n",
       "35  0.574673  0.812053  0.503787      0.838080  1.000000e-05\n",
       "36  0.572901  0.812912  0.501106      0.838559  1.000000e-06\n",
       "37  0.572479  0.812561  0.499855      0.838900  1.000000e-06\n",
       "38  0.572343  0.813112  0.499211      0.839034  1.000000e-06\n",
       "39  0.570565  0.813280  0.498555      0.839232  1.000000e-06\n",
       "40  0.571905  0.813147  0.498695      0.839132  1.000000e-06\n",
       "41  0.572994  0.812424  0.499348      0.838915  1.000000e-06\n",
       "42  0.571309  0.813074  0.499981      0.838698  1.000000e-06\n",
       "43  0.572335  0.813037  0.499490      0.838790  1.000000e-06\n",
       "44  0.569765  0.813773  0.499492      0.838749  1.000000e-07\n",
       "45  0.569673  0.813733  0.499142      0.838874  1.000000e-07\n",
       "46  0.569507  0.813960  0.499262      0.838827  1.000000e-07\n",
       "47  0.568974  0.814016  0.499555      0.838696  1.000000e-07"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = pd.concat([scores,pd.DataFrame(data=res.history)])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a2fb44c-908a-4236-9237-1f1defc093aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d354f226-9adc-4b3f-85a1-e7682ac4414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab740265-e4cd-4b17-851b-8b04b06d9a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores['accuracy'], label='Train Accuracy')\n",
    "plt.plot(scores['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.title(f'Accuracy after {len(scores)} epochs')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c297ce26-31b2-46c1-9f63-8a1e230c83a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores['loss'], label='Train Loss')\n",
    "plt.plot(scores['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title(f'Accuracy after {len(scores)} epochs')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c948cc64-634f-479b-a159-ec9e97823ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e891963-ecba-4e86-b633-b885c91e67c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f3ddaab34f7d1d9b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f3ddaab34f7d1d9b\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f744843-1c27-432d-9025-decfe32d5385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 s, sys: 0 ns, total: 5 s\n",
      "Wall time: 11.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c35bc-17b7-4b8c-80b4-cb1bbe141c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
